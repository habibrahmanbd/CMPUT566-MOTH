{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trial2 for d1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0-3-QdSaDX3",
        "outputId": "c9e8024a-24f3-4ffc-f86d-8fdad0e1b97b"
      },
      "source": [
        "#Ref1: https://www.analyticsvidhya.com/blog/2019/01/neural-machine-translation-keras/\n",
        "#Ref2: https://machinelearningmastery.com/develop-neural-machine-translation-system-keras/\n",
        "\n",
        "from pickle import load\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import string\n",
        "import re\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "from keras import backend as K\n",
        "from keras import __version__\n",
        "print('Using Keras version:', __version__, 'backend:', K.backend())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Keras version: 2.4.3 backend: tensorflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3K7iSwsRPf4"
      },
      "source": [
        "def read_dataset(file_path):\n",
        "    #Open from .txt files\n",
        "    dataset = []\n",
        "    with open(file_path, encoding='utf-8') as f:\n",
        "        dataset = f.readlines()\n",
        "        f.close()\n",
        "    return dataset\n",
        "\n",
        "def split_input_target(dataset):\n",
        "    datasetLength = len(dataset)\n",
        "\n",
        "    # Split into English Sentence and Portuguese Sentences\n",
        "    eng_sen =  [] #English Sentence\n",
        "    port_sen =  [] #Portuguese Sentence\n",
        "\n",
        "    for line in dataset:\n",
        "        splited = line.split('|')\n",
        "        eng_sen.append(splited[0])\n",
        "        port_sen.append(splited[1])\n",
        "\n",
        "    return [eng_sen, port_sen]\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0nOUOjYI9Tj"
      },
      "source": [
        "def cleaning_punctuation_and_uppercase(sentence_list):\n",
        "    sentence_list  = [((sen.strip()).translate(str.maketrans('', '', string.punctuation))).lower() for sen in sentence_list]\n",
        "    return sentence_list\n",
        "\n",
        "def visualize_length_of_sentences(title, senX, senY):\n",
        "    senX = [len(sen.split()) for sen in senX]\n",
        "    senY = [len(sen.split()) for sen in senY]\n",
        "    length_df = pd.DataFrame({'English': senX, 'Portuguese': senY})\n",
        "    length_df.hist(bins = 30)\n",
        "    plt.xticks(range(0, 15, 1))\n",
        "    plt.xlabel('#Word', fontsize=18)\n",
        "    plt.ylabel('#Sentences', fontsize=16)\n",
        "    fig = plt.figure()\n",
        "    fig.suptitle(title, fontsize=20)\n",
        "    #fig.save(title+\".jpg\")\n",
        "    plt.show()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QZfzsxWJkNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c1acf2-cc76-44a4-b118-0fb8f94f6cd6"
      },
      "source": [
        "def tokenizer(sentence_list):\n",
        "    tok = tf.keras.preprocessing.text.Tokenizer()\n",
        "    tok.fit_on_texts(sentence_list)\n",
        "    return  tok #tok.sequences_to_matrix(tok.texts_to_sequences(sentence_list), mode='tfidf')\n",
        "\n",
        "# Text Encoding into sequences and pad to make equal feature length to Train NN\n",
        "def encode_text_to_sequences(tokenizer, max_sen_length, sentence_list):\n",
        "    # integer encode sequences\n",
        "    seq = tokenizer.texts_to_sequences(sentence_list)\n",
        "    # pad sequences with 0 values\n",
        "    seq = keras.preprocessing.sequence.pad_sequences(seq, maxlen=max_sen_length, padding='post')\n",
        "    return seq\n",
        "\n",
        "def max_length(data):\n",
        "    mx = 0\n",
        "    for i in range(len(data)):\n",
        "        mx = max(mx, len(data[i]))\n",
        "    return mx\n",
        "\n",
        "# Validation Data Process\n",
        "validation_dataset = read_dataset(\"dev_best.txt\")\n",
        "val_eng_sen, val_port_sen = split_input_target(validation_dataset)\n",
        "\n",
        "val_eng_sen = cleaning_punctuation_and_uppercase(val_eng_sen)\n",
        "val_port_sen = cleaning_punctuation_and_uppercase(val_port_sen)\n",
        "\n",
        "print('Validation English Datalen: '+str(len(val_eng_sen)))\n",
        "print('Validation Portugu Datalen: '+str(len(val_port_sen)))\n",
        "\n",
        "# Test Data Process\n",
        "test_dataset = read_dataset(\"test.txt\")\n",
        "test_eng_sen, test_port_sen = split_input_target(test_dataset)\n",
        "\n",
        "test_eng_sen = cleaning_punctuation_and_uppercase(test_eng_sen)\n",
        "test_port_sen = cleaning_punctuation_and_uppercase(test_port_sen)\n",
        "\n",
        "print('Test English Datalen: '+str(len(test_eng_sen)))\n",
        "print('Test Portugu Datalen: '+str(len(test_port_sen)))\n",
        "    "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation English Datalen: 500\n",
            "Validation Portugu Datalen: 500\n",
            "Test English Datalen: 67865\n",
            "Test Portugu Datalen: 67865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_BGrEgiKxim",
        "outputId": "c04f2b6f-82f0-448a-c877-de84d2f877bb"
      },
      "source": [
        "    dataset = read_dataset(\"dataset_1.txt\")\n",
        "\n",
        "    #dataset = read_dataset(root + 'datasets/modified_datasets/dataset_'+str(i)+'.txt')\n",
        "    eng_sen, port_sen = split_input_target(dataset)\n",
        "\n",
        "    #Cleaning\n",
        "    eng_sen = cleaning_punctuation_and_uppercase(eng_sen)\n",
        "    port_sen = cleaning_punctuation_and_uppercase(port_sen)\n",
        "\n",
        "    #Plot Sentences\n",
        "    #visualize_length_of_sentences(\"modified dataset \"+str(i), eng_sen, port_sen)\n",
        "\n",
        "    #tokenize\n",
        "    eng_tok = tokenizer(eng_sen+val_eng_sen+test_eng_sen)\n",
        "    port_tok = tokenizer(port_sen+val_port_sen+test_port_sen)\n",
        "\n",
        "    #Max word length in Sentence\n",
        "    max_eng_sen_word_length  = max_length(eng_sen+val_eng_sen+test_eng_sen)\n",
        "    max_port_sen_word_length = max_length(port_sen+val_port_sen+test_port_sen)\n",
        "\n",
        "    #Vocab Size\n",
        "    eng_vocab_size = len(eng_tok.word_index)+1\n",
        "    port_vocab_size = len(port_tok.word_index)+1\n",
        "    print('English Vocab Size: ' + str(eng_vocab_size))\n",
        "    print('Portugu Vocab Size: ' + str(port_vocab_size))\n",
        "\n",
        "    #train encoding text to sequence\n",
        "    train_eng_enc_seq = encode_text_to_sequences(eng_tok, max_eng_sen_word_length, eng_sen)\n",
        "    train_port_enc_seq = encode_text_to_sequences(port_tok, max_port_sen_word_length, port_sen)\n",
        "\n",
        "    #validation enc text to seq\n",
        "    val_eng_enc_seq = encode_text_to_sequences(eng_tok, max_eng_sen_word_length, val_eng_sen)\n",
        "    val_port_enc_seq = encode_text_to_sequences(port_tok, max_port_sen_word_length, val_port_sen)\n",
        "\n",
        "    #test enc text to seq\n",
        "    test_eng_enc_seq = encode_text_to_sequences(eng_tok, max_eng_sen_word_length, test_eng_sen)\n",
        "    test_port_enc_seq = encode_text_to_sequences(port_tok, max_port_sen_word_length, test_port_sen)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocab Size: 2584\n",
            "Portugu Vocab Size: 5156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBC4ADewdxr0",
        "outputId": "624ef3bd-2523-4b5b-efff-575b3e3bfa0d"
      },
      "source": [
        "# define NMT model\n",
        "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, hidden_size):\n",
        "  use_dropout = True\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(src_vocab, hidden_size, input_length = src_timesteps, mask_zero=True))\n",
        "  model.add(LSTM(hidden_size))\n",
        "  model.add(RepeatVector(tar_timesteps))\n",
        "  model.add(LSTM(hidden_size, return_sequences=True))\n",
        "  if use_dropout:\n",
        "    model.add(Dropout(0.5))\n",
        "  model.add(TimeDistributed(Dense(tar_vocab, activation = 'softmax')))\n",
        "  \n",
        "  return model\n",
        "\n",
        "# define model\n",
        "model = define_model(eng_vocab_size, port_vocab_size, max_eng_sen_word_length, max_port_sen_word_length, 512)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "# summarize defined model\n",
        "print(model.summary())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 65, 512)           1323008   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 512)               2099200   \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 86, 512)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 86, 512)           2099200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 86, 512)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 86, 5156)          2645028   \n",
            "=================================================================\n",
            "Total params: 8,166,436\n",
            "Trainable params: 8,166,436\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b2NPeIi4ZhfJ",
        "outputId": "a7e85b64-8937-40b1-9cac-9e751f4e645c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root = '/content/gdrive/MyDrive/Colab Notebooks/CMPUT566/'\n",
        "\n",
        "filename = 'model.h1.d1_11_apr_21'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# train model\n",
        "history = model.fit(train_eng_enc_seq, train_port_enc_seq, epochs=50, batch_size=64, validation_split=0, validation_data = (val_eng_enc_seq, val_port_enc_seq), callbacks = [checkpoint], verbose=1)\n",
        "\n",
        "model.save('model.h1.d1_11_apr_21')\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Epoch 1/50\n",
            "63/63 [==============================] - 43s 118ms/step - loss: 3.0230 - val_loss: 0.7417\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.74168, saving model to model.h1.d1_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "63/63 [==============================] - 6s 92ms/step - loss: 0.7124 - val_loss: 0.6699\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.74168 to 0.66988, saving model to model.h1.d1_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.6448 - val_loss: 0.5615\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.66988 to 0.56149, saving model to model.h1.d1_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.5503 - val_loss: 0.4799\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.56149 to 0.47989, saving model to model.h1.d1_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.4942 - val_loss: 0.4834\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.47989\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.5017 - val_loss: 0.4680\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.47989 to 0.46804, saving model to model.h1.d1_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "63/63 [==============================] - 6s 97ms/step - loss: 0.4812 - val_loss: 0.4679\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.46804 to 0.46793, saving model to model.h1.d1_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "63/63 [==============================] - 6s 97ms/step - loss: 0.4659 - val_loss: 0.4587\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.46793 to 0.45870, saving model to model.h1.d1_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "63/63 [==============================] - 6s 96ms/step - loss: 0.4552 - val_loss: 0.4573\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.45870 to 0.45727, saving model to model.h1.d1_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "63/63 [==============================] - 6s 97ms/step - loss: 0.4476 - val_loss: 0.4543\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.45727 to 0.45429, saving model to model.h1.d1_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "63/63 [==============================] - 6s 96ms/step - loss: 0.4457 - val_loss: 0.4535\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.45429 to 0.45347, saving model to model.h1.d1_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "63/63 [==============================] - 6s 96ms/step - loss: 0.4349 - val_loss: 0.4502\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.45347 to 0.45021, saving model to model.h1.d1_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "63/63 [==============================] - 6s 96ms/step - loss: 0.4322 - val_loss: 0.4491\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.45021 to 0.44915, saving model to model.h1.d1_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "63/63 [==============================] - 6s 97ms/step - loss: 0.4292 - val_loss: 0.4510\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.44915\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.4254 - val_loss: 0.4511\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.44915\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 6s 97ms/step - loss: 0.4209 - val_loss: 0.4495\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.44915\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 6s 97ms/step - loss: 0.4192 - val_loss: 0.4500\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.44915\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 6s 96ms/step - loss: 0.4212 - val_loss: 0.4510\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.44915\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.4172 - val_loss: 0.4532\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.44915\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.4140 - val_loss: 0.4500\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.44915\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 6s 94ms/step - loss: 0.4094 - val_loss: 0.4518\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.44915\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 6s 94ms/step - loss: 0.4099 - val_loss: 0.4514\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.44915\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.4066 - val_loss: 0.4523\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.44915\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.4025 - val_loss: 0.4515\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.44915\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 6s 94ms/step - loss: 0.3993 - val_loss: 0.4538\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.44915\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.4026 - val_loss: 0.4517\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.44915\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 6s 94ms/step - loss: 0.3999 - val_loss: 0.4550\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.44915\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.3939 - val_loss: 0.4512\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.44915\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.3935 - val_loss: 0.4546\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.44915\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.3926 - val_loss: 0.4520\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.44915\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.3863 - val_loss: 0.4516\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.44915\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.3846 - val_loss: 0.4513\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.44915\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.3839 - val_loss: 0.4527\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.44915\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.3735 - val_loss: 0.4523\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.44915\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.3756 - val_loss: 0.4508\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.44915\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 6s 94ms/step - loss: 0.3729 - val_loss: 0.4519\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.44915\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 6s 94ms/step - loss: 0.3734 - val_loss: 0.4533\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.44915\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 6s 94ms/step - loss: 0.3722 - val_loss: 0.4575\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.44915\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 6s 94ms/step - loss: 0.3676 - val_loss: 0.4516\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.44915\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.3634 - val_loss: 0.4545\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.44915\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 6s 93ms/step - loss: 0.3631 - val_loss: 0.4511\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.44915\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.3546 - val_loss: 0.4539\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.44915\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.3555 - val_loss: 0.4519\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.44915\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.3530 - val_loss: 0.4512\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.44915\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.3481 - val_loss: 0.4505\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.44915\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.3440 - val_loss: 0.4485\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.44915 to 0.44852, saving model to model.h1.d1_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 47/50\n",
            "63/63 [==============================] - 6s 94ms/step - loss: 0.3454 - val_loss: 0.4499\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.44852\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 6s 94ms/step - loss: 0.3351 - val_loss: 0.4492\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.44852\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 6s 94ms/step - loss: 0.3324 - val_loss: 0.4472\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.44852 to 0.44720, saving model to model.h1.d1_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 50/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.3297 - val_loss: 0.4462\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.44720 to 0.44620, saving model to model.h1.d1_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d1_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUYfWWBw_waz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2405b7b3-77dc-4d25-9fa0-2cd6ca3acc49"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root = '/content/gdrive/MyDrive/Colab Notebooks/CMPUT566/'\n",
        "\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load(model_name):\n",
        "    return load_model(model_name)\n",
        "\n",
        "def get_word(n, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == n:\n",
        "            return word\n",
        "    return None\n",
        "\n",
        "def predicted_text(preds, out_tok):\n",
        "    pred_text = []\n",
        "    for i in preds:\n",
        "        temp = []\n",
        "        for j in range(len(i)):\n",
        "            t = get_word(i[j], out_tok)\n",
        "            if j > 0:\n",
        "                if (t == get_word(i[j-1], out_tok) or t == None):\n",
        "                    temp.append('')\n",
        "                else:\n",
        "                    temp.append(t)\n",
        "            else:\n",
        "                if t == None:\n",
        "                    temp.append('')\n",
        "                else:\n",
        "                    temp.append(t)\n",
        "        pred_text.append(' '.join(temp))\n",
        "    return pred_text\n",
        "\n",
        "\n",
        "model = load('model.h1.d1_11_apr_21')\n",
        "\n",
        "preds = model.predict_classes(test_eng_enc_seq, batch_size = 2048)\n",
        "\n",
        "pred_text = predicted_text(preds, port_tok)\n",
        "actc_text = predicted_text(test_port_enc_seq, port_tok)\n",
        "\n",
        "pred_df = pd.DataFrame({'actual' : actc_text, 'predicted' : pred_text})\n",
        "pred_df.sample(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}