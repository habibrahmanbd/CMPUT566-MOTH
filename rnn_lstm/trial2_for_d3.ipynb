{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trial2 for d3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0-3-QdSaDX3",
        "outputId": "e36d5f07-11f5-4c31-caab-c24f9f0fdd79"
      },
      "source": [
        "#Ref1: https://www.analyticsvidhya.com/blog/2019/01/neural-machine-translation-keras/\n",
        "#Ref2: https://machinelearningmastery.com/develop-neural-machine-translation-system-keras/\n",
        "\n",
        "from pickle import load\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import string\n",
        "import re\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "from keras import backend as K\n",
        "from keras import __version__\n",
        "print('Using Keras version:', __version__, 'backend:', K.backend())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Keras version: 2.4.3 backend: tensorflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3K7iSwsRPf4"
      },
      "source": [
        "def read_dataset(file_path):\n",
        "    #Open from .txt files\n",
        "    dataset = []\n",
        "    with open(file_path, encoding='utf-8') as f:\n",
        "        dataset = f.readlines()\n",
        "        f.close()\n",
        "    return dataset\n",
        "\n",
        "def split_input_target(dataset):\n",
        "    datasetLength = len(dataset)\n",
        "\n",
        "    # Split into English Sentence and Portuguese Sentences\n",
        "    eng_sen =  [] #English Sentence\n",
        "    port_sen =  [] #Portuguese Sentence\n",
        "\n",
        "    for line in dataset:\n",
        "        splited = line.split('|')\n",
        "        eng_sen.append(splited[0])\n",
        "        port_sen.append(splited[1])\n",
        "\n",
        "    return [eng_sen, port_sen]\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0nOUOjYI9Tj"
      },
      "source": [
        "def cleaning_punctuation_and_uppercase(sentence_list):\n",
        "    sentence_list  = [((sen.strip()).translate(str.maketrans('', '', string.punctuation))).lower() for sen in sentence_list]\n",
        "    return sentence_list\n",
        "\n",
        "def visualize_length_of_sentences(title, senX, senY):\n",
        "    senX = [len(sen.split()) for sen in senX]\n",
        "    senY = [len(sen.split()) for sen in senY]\n",
        "    length_df = pd.DataFrame({'English': senX, 'Portuguese': senY})\n",
        "    length_df.hist(bins = 30)\n",
        "    plt.xticks(range(0, 15, 1))\n",
        "    plt.xlabel('#Word', fontsize=18)\n",
        "    plt.ylabel('#Sentences', fontsize=16)\n",
        "    fig = plt.figure()\n",
        "    fig.suptitle(title, fontsize=20)\n",
        "    #fig.save(title+\".jpg\")\n",
        "    plt.show()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QZfzsxWJkNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d48e07ce-fbb4-4e92-def4-e6e426b06dc5"
      },
      "source": [
        "def tokenizer(sentence_list):\n",
        "    tok = tf.keras.preprocessing.text.Tokenizer()\n",
        "    tok.fit_on_texts(sentence_list)\n",
        "    return  tok #tok.sequences_to_matrix(tok.texts_to_sequences(sentence_list), mode='tfidf')\n",
        "\n",
        "# Text Encoding into sequences and pad to make equal feature length to Train NN\n",
        "def encode_text_to_sequences(tokenizer, max_sen_length, sentence_list):\n",
        "    # integer encode sequences\n",
        "    seq = tokenizer.texts_to_sequences(sentence_list)\n",
        "    # pad sequences with 0 values\n",
        "    seq = keras.preprocessing.sequence.pad_sequences(seq, maxlen=max_sen_length, padding='post')\n",
        "    return seq\n",
        "\n",
        "def max_length(data):\n",
        "    mx = 0\n",
        "    for i in range(len(data)):\n",
        "        mx = max(mx, len(data[i]))\n",
        "    return mx\n",
        "\n",
        "# Validation Data Process\n",
        "validation_dataset = read_dataset(\"dev_best.txt\")\n",
        "val_eng_sen, val_port_sen = split_input_target(validation_dataset)\n",
        "\n",
        "val_eng_sen = cleaning_punctuation_and_uppercase(val_eng_sen)\n",
        "val_port_sen = cleaning_punctuation_and_uppercase(val_port_sen)\n",
        "\n",
        "print('Validation English Datalen: '+str(len(val_eng_sen)))\n",
        "print('Validation Portugu Datalen: '+str(len(val_port_sen)))\n",
        "\n",
        "# Test Data Process\n",
        "test_dataset = read_dataset(\"test.txt\")\n",
        "test_eng_sen, test_port_sen = split_input_target(test_dataset)\n",
        "\n",
        "test_eng_sen = cleaning_punctuation_and_uppercase(test_eng_sen)\n",
        "test_port_sen = cleaning_punctuation_and_uppercase(test_port_sen)\n",
        "\n",
        "print('Test English Datalen: '+str(len(test_eng_sen)))\n",
        "print('Test Portugu Datalen: '+str(len(test_port_sen)))\n",
        "    "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation English Datalen: 500\n",
            "Validation Portugu Datalen: 500\n",
            "Test English Datalen: 67865\n",
            "Test Portugu Datalen: 67865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_BGrEgiKxim",
        "outputId": "622a602d-fac3-4776-d6cd-9fe7704c9b46"
      },
      "source": [
        "    dataset = read_dataset(\"dataset_3.txt\")\n",
        "\n",
        "    #dataset = read_dataset(root + 'datasets/modified_datasets/dataset_'+str(i)+'.txt')\n",
        "    eng_sen, port_sen = split_input_target(dataset)\n",
        "\n",
        "    #Cleaning\n",
        "    eng_sen = cleaning_punctuation_and_uppercase(eng_sen)\n",
        "    port_sen = cleaning_punctuation_and_uppercase(port_sen)\n",
        "\n",
        "    #Plot Sentences\n",
        "    #visualize_length_of_sentences(\"modified dataset \"+str(i), eng_sen, port_sen)\n",
        "\n",
        "    #tokenize\n",
        "    eng_tok = tokenizer(eng_sen+val_eng_sen+test_eng_sen)\n",
        "    port_tok = tokenizer(port_sen+val_port_sen+test_port_sen)\n",
        "\n",
        "    #Max word length in Sentence\n",
        "    max_eng_sen_word_length  = max_length(eng_sen+val_eng_sen+test_eng_sen)\n",
        "    max_port_sen_word_length = max_length(port_sen+val_port_sen+test_port_sen)\n",
        "\n",
        "    #Vocab Size\n",
        "    eng_vocab_size = len(eng_tok.word_index)+1\n",
        "    port_vocab_size = len(port_tok.word_index)+1\n",
        "    print('English Vocab Size: ' + str(eng_vocab_size))\n",
        "    print('Portugu Vocab Size: ' + str(port_vocab_size))\n",
        "\n",
        "    #train encoding text to sequence\n",
        "    train_eng_enc_seq = encode_text_to_sequences(eng_tok, max_eng_sen_word_length, eng_sen)\n",
        "    train_port_enc_seq = encode_text_to_sequences(port_tok, max_port_sen_word_length, port_sen)\n",
        "\n",
        "    #validation enc text to seq\n",
        "    val_eng_enc_seq = encode_text_to_sequences(eng_tok, max_eng_sen_word_length, val_eng_sen)\n",
        "    val_port_enc_seq = encode_text_to_sequences(port_tok, max_port_sen_word_length, val_port_sen)\n",
        "\n",
        "    #test enc text to seq\n",
        "    test_eng_enc_seq = encode_text_to_sequences(eng_tok, max_eng_sen_word_length, test_eng_sen)\n",
        "    test_port_enc_seq = encode_text_to_sequences(port_tok, max_port_sen_word_length, test_port_sen)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocab Size: 2584\n",
            "Portugu Vocab Size: 10381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBC4ADewdxr0",
        "outputId": "08cee74f-39cd-4362-d053-5f518f19c8be"
      },
      "source": [
        "# define NMT model\n",
        "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, hidden_size):\n",
        "  use_dropout = True\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(src_vocab, hidden_size, input_length = src_timesteps, mask_zero=True))\n",
        "  model.add(LSTM(hidden_size))\n",
        "  model.add(RepeatVector(tar_timesteps))\n",
        "  model.add(LSTM(hidden_size, return_sequences=True))\n",
        "  if use_dropout:\n",
        "    model.add(Dropout(0.5))\n",
        "  model.add(TimeDistributed(Dense(tar_vocab, activation = 'softmax')))\n",
        "  \n",
        "  return model\n",
        "\n",
        "# define model\n",
        "model = define_model(eng_vocab_size, port_vocab_size, max_eng_sen_word_length, max_port_sen_word_length, 1024)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "# summarize defined model\n",
        "print(model.summary())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 65, 1024)          2646016   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 1024)              8392704   \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 86, 1024)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 86, 1024)          8392704   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 86, 1024)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 86, 10381)         10640525  \n",
            "=================================================================\n",
            "Total params: 30,071,949\n",
            "Trainable params: 30,071,949\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "b2NPeIi4ZhfJ",
        "outputId": "4ad1296a-1f02-4c5f-e90a-19a2c75d86ac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root = '/content/gdrive/MyDrive/Colab Notebooks/CMPUT566/'\n",
        "\n",
        "filename = 'model.h1.d3_11_apr_21'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# train model\n",
        "history = model.fit(train_eng_enc_seq, train_port_enc_seq, epochs=5, batch_size=64, validation_split=0, validation_data = (val_eng_enc_seq, val_port_enc_seq), callbacks = [checkpoint], verbose=1)\n",
        "\n",
        "model.save('model.h1.d3_11_apr_21')\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Epoch 1/5\n",
            "8125/8125 [==============================] - 2044s 247ms/step - loss: 0.4531 - val_loss: 0.3466\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.34663, saving model to model.h1.d3_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d3_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d3_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/5\n",
            "8125/8125 [==============================] - 2028s 250ms/step - loss: 0.1877 - val_loss: 0.3456\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.34663 to 0.34559, saving model to model.h1.d3_11_apr_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d3_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d3_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/5\n",
            "8125/8125 [==============================] - 2021s 249ms/step - loss: 0.1432 - val_loss: 0.3544\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.34559\n",
            "Epoch 4/5\n",
            "8125/8125 [==============================] - 2016s 248ms/step - loss: 0.1335 - val_loss: 0.3587\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.34559\n",
            "Epoch 5/5\n",
            "8125/8125 [==============================] - 2002s 246ms/step - loss: 0.1283 - val_loss: 0.3658\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.34559\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d3_11_apr_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.d3_11_apr_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUYfWWBw_waz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "8978df73-601f-4006-8fac-68c38cce9555"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root = '/content/gdrive/MyDrive/Colab Notebooks/CMPUT566/'\n",
        "\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load(model_name):\n",
        "    return load_model(model_name)\n",
        "\n",
        "def get_word(n, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == n:\n",
        "            return word\n",
        "    return None\n",
        "\n",
        "def predicted_text(preds, out_tok):\n",
        "    pred_text = []\n",
        "    for i in preds:\n",
        "        temp = []\n",
        "        for j in range(len(i)):\n",
        "            t = get_word(i[j], out_tok)\n",
        "            if j > 0:\n",
        "                if (t == get_word(i[j-1], out_tok) or t == None):\n",
        "                    temp.append('')\n",
        "                else:\n",
        "                    temp.append(t)\n",
        "            else:\n",
        "                if t == None:\n",
        "                    temp.append('')\n",
        "                else:\n",
        "                    temp.append(t)\n",
        "        pred_text.append(' '.join(temp))\n",
        "    return pred_text\n",
        "\n",
        "\n",
        "model = load('model.h1.d3_11_apr_21')\n",
        "\n",
        "preds = model.predict_classes(test_eng_enc_seq, batch_size = 2048)\n",
        "\n",
        "pred_text = predicted_text(preds, port_tok)\n",
        "actc_text = predicted_text(test_port_enc_seq, port_tok)\n",
        "\n",
        "pred_df = pd.DataFrame({'actual' : actc_text, 'predicted' : pred_text})\n",
        "pred_df.sample(15)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-810846beb9c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h1.d3_11_apr_21'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_eng_enc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mpred_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport_tok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    457\u001b[0m                   \u001b[0;34m'  if your model does binary classification '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                   '  (e.g. if it uses a `sigmoid` last-layer activation).')\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       return self._concrete_stateful_fn._call_flat(\n\u001b[0;32m--> 895\u001b[0;31m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_kwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_filtered_flat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[176128,10381] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential/time_distributed/dense/Softmax (defined at <ipython-input-8-810846beb9c8>:42) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_predict_function_141655]\n\nFunction call stack:\npredict_function\n"
          ]
        }
      ]
    }
  ]
}